% vim:textwidth=70
\chapter{可自管理的分布式应用管理系统}
\label{chap:selfman}

%问题，相关工作，创新点，基本\textbf{方法}，实验

%问题提出：管理系统是一个分布式应用，同样需要管理
%
%目前的办法：集中部署启动管理系统到各个机器上，并集中式探测、维护（需要
%确认，或者说确定目前方法的缺陷）
%
%集中式的：plush，smartfrog，app-manager，globus，cfengine，还有
%
%plush, app-manager, smartfrog, cfengine, globus, amazon ec2
%
%==========
%为什么要管理管理系统：部署是必须的。更新是必须的。监测呢？可以用cron。
%
%ec2上可以用预装了plush的AMI
%
%攻击点：部署和更新也不经常有，监测死活可以用cron，管理节点死了几个也没事，
%早晚会发现，在那么大规模上，节点多几个少几个没太大问题。
%
%目前管理管理系统的办法有什么不足：
%
%一个可能得点：象self-host文章说的那样，说app希望可以改变运行的节点
%===========
%
%基本方法：节点相互探测对方状态，依据探测的结果，进行相应的管理步骤，实现
%
%系统的自管理。
%
%挑战：可扩展，鲁棒稳定，支持安全的自动认证，扩展管理能力(?)
%
%设计理念：简单、无状态(microreboot?)

\section{本章引言}

分布式系统~\cite{Ghemawat2003,DeCandia2007}是当今internet服务~
\cite{google, amazon?}的关键组成部分。随着普通计算机硬件成本越来越低，
搭建一个规模成百上千的分布式计算平台是很普通的事情。一些常见的分布式计
算平台包括Planet-Lab~\cite{Bavier2004}, Amazon
EC2~\cite{Garfinkel2007} and Teragrid~\cite{Catlett2002}。这些计算平台
可以提供大容量的存贮能力和巨大的计算能力，因此，设计良好的应用可以充
分利用这些资源来提升自己的性能。

随着分布式应用的规模越来越大，有效的管理它们越来越有挑战性。分布式应用
管理系统就是用来简化部署和维护分布式应用的系统。为了有效的完成管理
任务，管理系统也被设计为一个复杂的分布式系统。一个管理系统包括运行在不
同机器上的若干“节点\footnote{对于采用集中式算法的管理系统，节点就是所
谓的客户端}”。这些管理节点间形成一个覆盖网络，节点相互合作来部署分布
式应用。当分布式应用被部署并启动以后，这些管理节点可以监测并维护运行在
同一机器内的应用节点。管理员可以通过管理系统查询应用的状态，或者按照需
求向应用发送控制命令。

我们注意到，由于管理系统实际上也是一个分布式系统，或者说分布式应用，这
带来了一个重要的问题：管理系统也需要被管理。首先，需要把管理节点部署到
一组机器上去，其次，\note{这里需要想想怎么说}

在本文中，我们提出了可自管理的覆盖网络（SMON, Self-Managed Overlay
Network）。SMON是一个新颖的分布式应用管理系统，它具有内建自管理能力，
包括自我部署、自我更新和自我恢复能力。因而，它有效的解决了分布式管理系
统也需要管理的问题。SMON包括分布在一组机器上的管理节点，这些节点相互探
测对方的状态，依据探测的结果，自动执行自我管理任务，包括安装新的SMON管
理节点、更新SMON管理节点至新的版本，或者恢复失败的SMON管理节点。这样，
从整体来看，SMON具有了自我管理的能力。

作为一个分布式应用管理系统，SMON提供了一组基本的管理语意。\note{应用管
理，拓展管理能力。}

设计SMON需要解决一下几个挑战性问题。

首先，SMON需要有良好的可扩展性。其次，为了让SMON节点能够自动在远程机器
上安装新的SMON节点，或者恢复失败的节点，需要有安全机制使SMON节点能够自
动与远程机器认证并登陆，同时保护用户的认证信息（例如私钥）不会被泄露。
最后，SMON的管理能力应该是能够被拓展的。

SMON的设计分别处理了上面几个问题，叙述如下。对第一个问题，SMON的节点构
成一个无结构的覆盖网络，节点间使用epidemic算法相互探测，并执行管理任务。
epidemic算法保证了SMON系统具有良好的扩展性（$O(\log N)$），同时
epidemic算法也带来了额外的好处，首先它易于实现，其次，它使得SMON系统很
鲁棒，可以很好的应对网络分割（network partition）错误。对于第二个问题，
我们引入了一个认证代理来帮助SMON节点与远程机器认证。认证代理保存着认证
过程中需要的认证信息（例如私钥），它并不将认证信息泄露给任何SMON节点，
或其它外部对象。简单的说，SMON节点会将认证过程中收到的挑战密文（
challenge）转发给认证代理，并将认证代理回复的应答密文（response）发送
给远程机器，从而完成了自动认证的过程。对于第三个问题，我们可以在SMON上
面部署新的管理系统来扩展系统整体的管理能力。这样，任何部署在SMON之上的
分布式应用，都具有了自管理的能力。

本章接来下的部分安排如下：\ref{sec:smon_design}节描述如何设计SMON系统，
包括如何实现自我管理，SMON的安全机制、邻居列表维护与应用管理语意的实现。
\ref{sec:smon_impl}节描述了如何在Planet-Lab上实现SMON。
\ref{sec:smon_app}节展示了SMON系统的一些使用方式。我们在Planet-Lab上评
测了SMON系统的性能参数，其结果展示在\ref{sec:smon_eval}节。
\ref{sec:smon_related}节讨论了相关工作。\ref{sec:smon_conclusion}为本
章小结。


\section{系统设计}
\label{sec:smon_design}

\begin{figure}
  \centering
  \begin{minipage}{0.8\linewidth}
    \centering
    \includegraphics[width=3.0in]{smon_arch}
    \caption[SMON系统结构]{SMON系统结构。SMON系统由三部分构成，
    SMON管理节点、认证代理和
    客户端工具。SMON节点构成SMON系统的主要部分，认证代理协助SMON节点与远程
    机器认证，使用者通过客户端工具完成管理任务。}
    \label{fig:smon_arch}
  \end{minipage}
\end{figure}

SMON系统的体系结构如图~\ref{fig:smon_arch}所示，包含了三个部分：SMON节
点，认证代理和客户端工具。

SMON管理节点运行在分布式平台的一组机器上，每个节点都维护着完整的机器列
表，这个列表也称作是SMON节点的邻居列表。SMON节点相互探测并相互维护。
SMON节点定期从从邻居列表中选择一个节点，向它发一个ping消息，如果超时没
有收到回复的pong消息，那么这个SMON节点会试图向远程机器安装新的SMON节点，
如果远程机器已经安装有SMON节点，那么它将会试图恢复失败的SMON节点运行。
每个SMON节点都保存着自身的版本号，在用ping-pong消息相互探测过程中，会
顺便交换相互的版本号，低版本的SMON节点会将自身升级至高版本。

认证代理持有与分布式平台上的机器认证所需的认证信息（例如私钥）。当
SMON节点在远程机器上部署新的SMON节点，或者恢复失败的SMON节点时，需要首
先与远程机器认证并登陆，这一过程需要认证代理的协助。

用户使用客户端工具来管理一组分布式应用，这其中包括其它分布式管理系统。
通过这个办法，我们可以不断扩充SMON的管理能力。\note{这个说法需要斟酌。}

\subsection{自我管理设计}

我们分别描述SMON自我管理的三个方面：自我部署，自我更新和自我恢复。

\subsubsection*{自我部署}

% 一些啰嗦的表达方式：
% SMON可以自动部署至一组节点，一组分布式节点
% 相互探测，相互维护
% ping -> liveness

SMON可以自动将自己部署至分布式平台的一组目标机器上去。在最初状态时，所
有的目标机器上都没有被部署运行SMON节点。用户需要手动部署并启动一个SMON
节点。这个SMON节点会在邻居列表中随机选取一个机器，并在它上面部署第二个
SMON节点。新的SMON节点同样会在别的机器上部署SMON节点。当越来越多的SMON
节点被部署，自我部署过程会以幂指数速度增长。可以证明，以概率1，
所有可以连接的机器上都会被部署SMON节点~\cite{Eugster2004}。

详细来说，节点$P$会定期选择邻居列表里的一个机器$M$，并向它上发送SMON节
点探测消息（ping）。如果超时没有收到回应的pong消息，$P$就会在$M$上远程
部署一份SMON节点。它首先在认证代理的协助下（在\ref{subsec:security}节
中描述）认证并登陆进$M$，向$M$远程拷贝一份SMON的安装程序，并远程启动安
装程序。启动的安装程序首先检查自己的完整性（使用checksum校验和），以防
传输过程中产生错误，然后它会安装并启动SMON节点。

在上述过程运行的任何时刻，都有可能因为外界因素而产生错误（例如连接中断，
机器崩溃等）。如果有错误发生，$P$会直接放弃这次远程部署的任务。
epidemic算法能够保证，在未来，$M$会被另外一个SMON节点$P'$选中并部署
SMON节点。

自我部署过程中存在着竞争情形（race condition）。因为采用了epidemic算法，
多个SMON节点可能同时试图向同一个机器$M$部署SMON节点。这个问题不需要
SMON节点间直接协调便可以解决。不同SMON节点会将安装程序远程复制到$M$上的
不同目录，相互不会覆盖。如果有多份安装程序被同时启动，它们会使用操作系
统提供的同步机制（例如lock file），保证只有一份安装程序能够运行。因此，
只有第一个运行的安装程序能够完成安装。在解决这个竞争情形的过程中，引入
了一定的额外开销，会有多份安装程序被拷贝至同一台机器。这会浪费一部分存
储资源和网络带宽。经过实验测试，可以看出额外开销的数量在多大数机器上是
很小的。同时考虑到安装程序很小，只有122KB，因此可以认为额外开销的影响
不大。

自我部署过程何时结束是难以严格确定的。理想情况是，当所有目标节点上都被
部署并运行着SMON节点时，自我部署过程就可以称为结束了。但是，在分布式环
境下，某些节点可能会发生错误，或者不可连接，所以，实际情况下自我部署过
程很难达到理想情况。即使一个机器已经被部署了SMON节点，也有可能因为机器
或者网络错误的原因，造成某些SMON节点被关闭或者不可连接。因此，为了应对
分布式环境频繁发生的异常错误，每个SMON节点需要不断的监控其它节点。自我
部署何时结束是一个需要用户定义的问题。用户可以查询有多少机器已经部署且
运行着SMON节点，根据需要决定自我部署是否结束。

\subsubsection*{自我更新}

SMON可以将自己自动更新至新的新的版本。这个更新过程是在线进行的，用户不
需要因为更新而停止整个SMON系统。

每个SMON节点都有版本号，版本号被持久保存在每个SMON节点的配置文件中。
SMON节点会以epidemic方式交换相互的版本号。当发现相互的版本不同，版本低
的SMON节点会自动从高版本SMON节点那里获取新的安装程序，将自己更新至高版
本。为了把整个SMON系统更新至新版本，用户只需要更新一个SMON节点，整个
SMON系统会逐渐收敛至一个最终的版本。用户使用~\ref{subsec:client}节中描
述的客户端工具更新任何一个SMON节点。

存在着多个SMON节点向同一个版本SMON节点请求安装程序的可能，为了防止
瞬间拥挤（flash crowd）的冲击，节点会限制同时请求安装程序的数量。

\subsubsection*{自我恢复}

SMON系统可能遇到两种分布式环境中产生的错误：机器失败和网络分割。当一个
机器失败时，它上面运行的SMON节点也同时会被停止。SMON节点会尝试重新启动
失败的SMON节点，因此一旦失败的机器恢复，它上面的SMON节点会被重新启动。
同时启动多份SMON节点的实例是安全的，使用操作系统的同步机制，这等同于只
启动一个SMON实例。

网络分割也很容易应对。当网络分割发生时，SMON系统被分割为多个部分，每个
部分将会成为一个独立的小SMON系统，它们的状态，例如运行的SMON节点版本，
都将在各个部分内逐渐达成一致。当被分割的部分重新连接上时，不同部分的
节点会重新相互联系，从而整个系统的状态逐渐收敛。

\subsubsection*{自我管理小结}

将上述三个部分合并起来，就构成了SMON自我管理的内容。SMON节点通过相互探
测并执行相应的管理任务来达到整个SMON系统自我管理的目标。有两点值得说明。
第一、作为一个优化，SMON间使用ping-pong消息探测时，会顺便交换
（piggyback）它们的版本号。第二、如果节点$A$认为节点$B$失败，可能有两
个原因，或者$B$没有运行，或者$B$所在机器没有部署SMON节点。$A$会首先判
断远程机器上是否部署了SMON，并采取相应的步骤。

\subsubsection*{禁止、启动自我管理功能}

SMON的自我管理功能应该是能够被显式的禁止或者启动的。考虑如下场景：某个
研究人员使用SMON部署了一个分布式系统原型，在进行一些实验后，他决定停止
部署的分布式系统和SMON。如果SMON的自我管理功能没有被禁止，则整个SMON系
统不能够被停止。任何被用户停止的SMON节点，都很快会被其它SMON节点启动，
除非用户能够在一瞬间停止所有SMON节点，然而这在大规模分布式系统上是不可
能。

我们使用一个布尔变量\texttt{livetag}控制SMON节点的自我管理功能。如果它
的值是假，则节点停止定期探测其它节点的活动，因此整个系统停止了自我管理
的功能。这样，我们就能够逐一停止SMON节点，从而停止整个SMON系统了。

\texttt{livetag}变量有一个关联的版本号，每个SMON节点维护着变量的一个复
本。两个随机节点会定期交换\texttt{$<$livetag, version$>$}对，并且更新
\texttt{livetag}到最新的版本。需要注意到，节点交换\texttt{livetag}的行
为也是收到\texttt{livetag}值的控制的。当\texttt{livetag}值为假，节点不
会主动要求交换\texttt{$<$livetag, version$>$}对，但是任然会对交换消息
回复，这能够加快更新\texttt{livetag}的速度。

\subsection{安全机制}
\label{subsec:security}

SMON的安全机制需要保证如下两个目标：

\begin{itemize}

  \item 让节点能够自动与其它机器认证并登陆，从而节点能够自动安装新的
  SMON节点，或者远程恢复失败的SMON节点。

  \item 认证并加密SMON节点间的通信，不让系统被恶意利用，被用来部署
  恶意应用，例如botnet~\cite{botnet}。

\end{itemize}

我们首先叙述如何在Planet-Lab上设计达到上述两个目标的安全机制，并解释如
何在其它分布式计算平台上应用这个机制。Planet-Lab使用公钥系统来认证对系
统平台的访问。每个用户使用ssh访问他的slice~\footnote{Planet-Lab分配给
用户的一组分布式资源，表现形式是一组分布式虚拟机。}。用户私钥保存在
自己的机器上，对应的公钥被分发到用户slice的所有虚拟机里。

\begin{figure}
\centering
  \begin{minipage}{0.8\linewidth}
    \centering
    \includegraphics[width=3.0in]{auth}
    \caption{SMON节点在认证代理协助下与远程机器认证并登陆的过程。图显示
    了这一过程中三者的交互过程。}
    \label{fig:auth}
  \end{minipage}
\end{figure}

SMON引入了认证代理来协助节点自动与远程机器认证。认证代理持有用户私钥，
但私钥并不会被泄露。如图~\ref{fig:auth}所示，当SMON节点需要登陆到其它
机器上时，它首先连接远程机器的sshd服务器，并发送登陆请求。sshd服务器会
返回一个认证挑战密文，SMON节点没有用户私钥，无法求解对应的应答密文，它
会直接将挑战密文转发给认证代理，认证代理使用用户私钥求解得到应答密文，
并告诉SMON节点。SMON节点再将应答密文发送给sshd服务器。这样，SMON节点能
够登陆到用户slice内的任何一台机器上，并且用户私钥并未被泄露。

我们使用一个对称密钥$K_E$来认证和加密SMON节点之间、SMON节点和认证代理
之间的通信。$K_E$在SMON节点部署时一同被部署到各个机器上。由于部署的过
程中，通信是加密的，因此$K_E$不会被泄露。$K_E$也是可以安全保存在slice
内的机器上的，因为slice的虚拟机之间被很好的相互隔离。

用户应仔细评估并选择认证代理运行的机器，保证用户私钥的安全。认证代理不
必运行在用户slice内的某个机器上。如果SMON被部署的规模非常大，可以考虑
运行多份认证代理，提高认证的性能，同时有效的应对网络分割错误。SMON节点
可以在DNS服务器协助下~\cite{dns_akamai}，将选择离自己最近的认证代理。

上面叙述的安全机制可以推广应用到其它分布式平台上，如果分布式平台满足下
面的两个假设：

\begin{itemize}
  \item 使用挑战-回应类型的认证方式，例如公钥认证机制，或密码认证机制。
  
  \item $K_E$可以安全的与SMON节点一起保存。
\end{itemize}

这两个假设可以被很多分布式平台满足，因此使用认证代理的安全机制可以被广
泛应用，例如Amazon EC2平台。在EC2平台上，用户使用ssh和他的私钥来访问一
组分布式虚拟机，这与Planet-Lab平台的情形非常类似。另外，私有集群，例如
学校或者企业内部的集群也可以应用认证代理安全机制。在这些集群上，一般都
安装使用Linux系统，访问集群内机器的方式也是ssh加用户私钥。虽然集群不一
定使用虚拟机隔离用户的资源，但是系统的用户都是非恶意的，因此$K_E$也可
以安全的保存在各个机器的本地文件系统上。另外，可以使用文件权限等工具，
进一步保护$K_E$的安全。

\subsection{邻居列表维护}

SMON系统的邻居列表有其自身的特点。一般来说，在其它分布式系统中，邻居列
表维护着一组正在运行的节点，而在SMON中，邻居列表是一组应该运行着SMON节
点的机器。SMON节点失败并不会影响邻居列表的内容。这个列表由SMON的用户指
定，并且通常不会发生改变。另外SMON系统要求，即使只有一个SMON节点在运行，
它也应该能够知道所有其它的目标管理机器。这意味着，任何SMON节点，都应该
能够知道整个目标管理机器列表。

在目前的设计使用了一个简单而实用的方案：每个SMON节点都维护着整个目标机
器列表的一个复本，列表通过压缩的方式存储在各个机器上。邻居列表有关联的
版本好，SMON节点会用epidemic的方式随机交换邻居列表的版本号，并更新旧版
本的邻居列表。通过改变邻居列表，用户可以改变SMON运行在哪些机器上。

这个邻居列表维护方案足够应用在上万规模的系统上。由于列表中只需要包含一
组节点的IP地址或者主机名称，一个简单的计算表明，用zip格式存储15000+规
模的节点列表，只需要大约100K的存储空间，这是可以接受的。

当邻居列表改变时，新添加的机器上会被自动部署新的SMON节点。从邻居列表中
删除的机器上的SMON节点也会在与其它节点交换邻居列表版本时，更新自己的邻
居列表，从而得知自己从列表中被删除。但是，它仍旧会不断的向新邻居列表中
的节点交换邻居列表版本与发送ping消息。这样，就帮助加快了散播邻居列表改
变的消息，同时帮助在新添加的机器上部署新的SMON节点。当大部分SMON节点更
新了它们的邻居列表时，SMON系统已经迁移到了一组新的机器上，位于列表中被
删除机器上的SMON节点将会很少收到来自其它节点的消息，这些SMON节点会在长
时间未收到消息的情况下，自动停止自己的运行。

\subsection{应用管理}

SMON可以管理若干个其它分布式应用。每个SMON节点负责部署和维护和它运行在
同一个机器内的分布式应用节点~\footnote{也就是分布式应用的进程}。每个应
用由它的名字所唯一标识。SMON节点会使用epidemic算法，定期与一个随机选择
的SMON节点交换它们管理的应用名称，如果发现一个新的未部署的应用，它会从
对方获取应用的安装程序，并在本机器部署安装新的应用。

应用被部署并启动后，会被同一机器上运行的SMON节点所监视并维护。应用可以
有两种状态，运行或停止。作为维护选项，用户可以指定应用应该出于哪一种状
态，可以有三种选择：

\begin{itemize}
  \item 始终在线（online）：应用应始终在线，如果应用停止了，会被立即重
  新启动。

  \item 始终离线（offline）：应用应始终离线。运行的应用会被停止。

  \item 忽略（ignore）：仅在应用部署后启动应用，之后就不再监视应用的状
  态。
\end{itemize}

这三个维护选项指明了SMON应该如何维护一个被管理的分布式应用，这在应用被
部署时一同包含在配置文件中。用户也可以在应用部署后单独改变某个应用节点
的维护选项。SMON节点会定期向应用指定的一个中心节点报告应用的状态。当应
用的状态改变时，SMON会立即向那个中心节点报告这个变化。

显然，SMON提供的应用监测与维护语意是很基本的。对于一些情况，这样的管理
语意是足够的，例如维护一个需要长期运行的分布式应用，应用的节点需要尽可
能处在运行状态。由于这样的应用一般都经过一定测试，相对稳定，因此重启失
败的节点是恢复应用的直接手段。SMON提供的管理语意只考虑了应用是否运行，
而没有进一步监视应用是否运行在正确状态，包括应用的安全性与活性（safety
and liveness）。为了扩展管理语意，增加新的管理功能，用户可以在SMON上部
署其它的分布式应用管理系统。这在~\ref{sec:smon_app}节有进一步论述。

\subsection{客户端工具}
\label{subsec:client}

用户可以用SMON的客户端工具来控制SMON。客户端工具和SMON节点之间的通信受
到对称密钥$K_E$认证和加密保护。为了部署一个新SMON系统，客户端工具会在
用户指定的一台机器上远程部署并启动一个SMON节点，之后，SMON会自动将自己
部署到用户指定的邻居列表内的机器上去。为了更新SMON系统，客户端工具将自
己模拟为一个SMON节点，并和任意一个SMON节点发送交换版本号消息，从而，那
个SMON节点会从客户端工具获取新的SMON安装程序，并更新自身，接下来，整个
SMON系统都会得到更新。类似的，用户可以使用客户端工具来部署新的分布式应
用程序，更新邻居列表，禁止与启动SMON的自我管理功能，等等。SMON系统的最
新版本号，以及邻居列表、\texttt{livetag}的最新版本号也由客户端工具维护，
集中保存在用户的机器上。最后，SMON节点实现了一组RPC，用户可以使用客户
端工具调用远程SMON的RPC，查询SMON节点的状态、应用的状态，以及管理分布
式应用，改变应用某个节点的维护选项。

\section{实现细节}
\label{sec:smon_impl}

我们针对Planet-Lab平台设计了SMON原型系统。Planet-Lab是一个全球范围的分
布式计算平台，它包含了超过400个站点，规模超过800个节点。使用
Planet-Lab的用户需要注册一个账号，并将账号与一个或多个slice相关联。
slice是Planet-Lab分配分布式资源的方式，一个slice对应分布在不同节点上的
一组虚拟机。用户可以使用ssh以公钥认证的方式登录他的slice里的机器。

我们使用Python语言实现SMON系统原型。最终的SMON节点安装程序大约122KB大
小，包括超过1000行代码。

我们使用单独的线程实现SMON节点运行时的epidemic活动。包括一个探测并维护
其它节点，实现自我管理功能的线程，一个更新邻居节点线程，一个更新
\texttt{livetag}的线程。对每一个应用，我们启动一个单独的管理与维护线程。

\begin{table*}
\small
\centering
\caption{SMON节点通信使用的RPC}
\label{fig:smon_rpc}
\begin{tabular}{|l|p{7cm}|}

\hline
\textbf{RPC} & \textbf{功能描述} \\

\hline
\texttt{ping(ver)} & Call with local SMON peer's version and
return remote peer's version.\\

\hline
\texttt{retrieve\_peer(ver)} & Retrieve installation package
of SMON peer with specified version.\\

\hline
\texttt{exchange\_livetag(tag, ver)} & Call with local
$<$livetag, version$>$, and return remote peer's $<$livetag,
version$>$.\\

\hline
\texttt{exchange\_member(ver)} & Call with local membership
list version and return remote peer's membership list.\\

\hline
\texttt{retreive\_member(ver)} & Retrive membership list of
specified version.\\

\hline
\texttt{exchange\_app(app\_name)} & Call with an application
name, return true if remote peer has installed the
application.\\

\hline
\texttt{retrieve\_app(app\_name)} & Retrieve installation package
of an application with specified name.\\

\hline
\texttt{resolve\_challenge(challenge)} & Return the response
to an authentication challenge.\\

\hline
\texttt{set\_app\_status(app\_name, status)} & Set application status (online,
offline, ignore).\\

\hline
\texttt{get\_app\_status()} & Get application status. \\

\hline

\end{tabular}
\end{table*}


SMON节点间的通信使用RPC机制实现，总结在表~\ref{fig:smon_rpc}中。

SMON节点通过spawn一个ssh/scp进程来远程复制安装程序或者执行命令。我们使
用修改的\texttt{ssh-agent}将ssh认证时的挑战密文转发给认证代理，实现自
动认证的过程。认证代理实现了RPC接口\texttt{resolve\_challenge}，其输入
参数是认证的挑战密文，返回对应的应答密文。

SMON节点运行时的参数保存在一个配置文件中。包括连续epdemic活动之间的时
间间隔，SMON节点和邻居列表的版本号，$<$\texttt{livetag, version}$>$对，
以及认证代理的地址。每个应用也可以指定应用状态变化时目标报告节点的地址。
配置文件用SQLite数据库实现，保证数据不会在机器崩溃时丢失。配置文件由
SMON节点与应用的安装程序更新。邻居列表单独保存在一个压缩文件中。


\section{应用方式}
\label{sec:smon_app}
plush

d3s

scalpel

\section{性能评价}
\label{sec:smon_eval}

我们在Planet-Lab平台上评测了SMON系统的性能指标。Planet-Lab是一个全球范
围的分布式计算平台，它包含了超过400的站点，规模超过800个节点。具体的说，
通过评测，我们能够看出，SMON系统的自我部署过程是有效的，并且有很好的可
扩展性。在自我部署过程中由于竞争情形引发的额外开销是足够小的，另外，
SMON系统的自我管理功能能够很快的在禁止和启动状态间转换。

\begin{figure}
\centering
  \begin{minipage}{0.8\linewidth}
    \centering
    \includegraphics[scale=0.618]{self-deploy.png}
    \caption{SMON在159个Planet-Lab机器上自我部署的进度}
    \label{fig:self-deploy}
  \end{minipage}
\end{figure}

首先，我们试图让SMON在159台Planet-Lab节点上完成自我部署，并观测部署性
能。我们在随机选取的一个Planet-Lab节点上，部署并启动了一个SMON节点，自
我部署过程开始。在目前设计中，SMON节点每隔5秒种，随机探测其它1个节点。
我们最终收集到154个节点上的数据，其它5个节点由于连接不上，因此它们的结
果不能取得。这种情况在大规模分布式系统中是很常见的。图~
\ref{fig:self-deploy}总结了部署过程的进度。我们可以看出，90\%（143个）
的节点，在149秒内被成功的部署了SMON节点。部署时间的中值是93秒，最后一
个节点被部署的时间是533秒。图~\ref{fig:self-deploy}中的“尾巴”是由于
两个原因造成的，一些机器由于负载太重，因此反应迟钝，另外连接至一些机器
的网络速度太慢，因此部署的速度比较慢。

\note{为什么曲线是先快后慢}

\note{overhead的模型？}

\begin{figure}
\centering
  \begin{minipage}{0.8\linewidth}
    \centering
    \includegraphics[scale=0.618]{state-trans.png}
    \caption{SMON的自我管理功能从禁止到启动过程的进度}
    \label{fig:state-transition}
  \end{minipage}
\end{figure}

SMON系统能够在活跃和非活跃状态间转换是非常重要的。我们在这里评测它状态
转换的性能。我们让在159个Planet-Lab节点上部署的SMON系统，从非活跃状态
变成活跃状态。图~\ref{fig:state-transition}总结了转换的进度。对于90\%
的节点来说，状态在143秒后成功的转换，而状态转换的中值是37秒。可以看出，
状态转换过程是非常快的。

\begin{figure}
\centering
  \begin{minipage}{0.8\linewidth}
    \centering
    \includegraphics[scale=0.5]{overhead.png}
    \caption{为了解决自我部署过程中的竞争情形而产生的额外开销分布。}
    \label{fig:overhead}
  \end{minipage}
\end{figure}

在自我部署过程中，存在着竞争情形，也就是多个SMON节点可能会在同一个机器
上部署新的SMON节点，这将引发额外开销。这个开销将会浪费网络和节点的存储
资源。我们计算了在每个机器上，发生的同时部署个数。结果显示在图~
\ref{fig:overhead}中。可以看出，有43.71\%的机器，只被部署了一次，对于
大部分机器，部署次数都在10以内，这样的机器覆盖了机器总数的92.04\%。平
均来说，每个机器被部署了4.30次，而部署次数在10以内的机器，它们的平均部
署次数是2.31。这样的结果表明，为解决竞争情形而引发的额外开销是可以接受
的。

\begin{table}
\centering
  \begin{minipage}{0.8\linewidth}
    \centering
    \caption{在不同的规模SMON自我部署性能比较}
    \label{fig:scalability}
    \begin{tabular}{|l|c|c|}
    \hline
           & 24 nodes & 159 nodes\\
    \hline
    median & 58 sec & 82 sec \\
    \hline
    90\%完成 & 85 sec & 149 sec\\
    \hline
    最终完成 & 103 sec & 533 sec\\
    \hline
    \end{tabular}
  \end{minipage}
\end{table}

为了评测自我部署过程的可扩展性，我们比较了在不同规模下部署SMON系统的性
能。我们在另外的24个节点上部署了新的SMON系统。表~\ref{fig:scalability}
总结并对比了在两个规模下的部署性能。从表中我们可以看出，两个系统规模的
比例是6.6（159/24），但是90\%进度的部署时间比例只有1.75（149/85），而
部署时间中值的比例是1.41（82/58）。可以看出，SMON系统具有良好的扩展性。

\section{相关工作}
\label{sec:smon_related}

\section{本章小结}
\label{sec:smon_conclusion}
