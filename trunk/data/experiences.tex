% vim:tw=60

\section{Experiences}
\label{sec:exp}

\notes{any rational? What is the point? It is effective on
what? and why}

\subsection{Understanding runtime behaviour}

We try to use the mined data hierarchy from logs to
understand runtime behaviour of cosmos client and EN server.
Cosmos is a distributed storage system similiar to GFS. The
EN server is similiar to the role of chunkserver. In cosmos,
data is organized in streams and streams are comprised of
extents. Each stream and extent is identified by a GUID.

We choose (Session, opId) to analyze cosmos client runtime
and choose ExtentID to analyze EN server runtime.

At the client side, we upload several files into cosmos and
query the streams status. We apply task model Session $:=$
opId$+$ on cosmos client log to investigate its runtime
behaviour. We successfully divide the activities of each
threads by Session and Opid.

There is one client thread who receives user commands and
each command is run as a session. A command is executed in
steps as different opId. Within a opId, it issues several
RPC calls. The client thread does not run the RPC calls, but
puts them into a queue. Other threads are workers who get
RPC calls and run them. When the responses for RPC calls are
returned, the workers notify the client threads on the
results. The workers does not know the session concept and
their activities are divided by opIds. The client and worker
threads activities can be connected by the same opId.

\begin{figure}
\centering
\includegraphics[height=1.5in]{ph}
\caption{The process of create a stream at client side.}
\label{fig:createstream}
\end{figure}

We look at how a file is uploaded into cosmos as stream
specifically. The process of create a stream at client side
is executed as four opIds and six RPC commands, as shown in
Figure~\ref{fig:createstream}. They are (create a stream),
(append stream, append extent), (append extent), (append
extent and seal the extent). Each parentheses indicate a
different opId. As the file size is smaller than the maximux
allowed extent size, the created stream contains only one
extent, and its content is sent by three append RPC calls.
After the last appending extent request, the extent is
sealed and no further append is allowed.

\begin{figure}
\centering
\includegraphics[height=1.5in]{ph}
\caption{Create and append extent at EN side.}
\label{fig:createextent}
\end{figure}

We then investigae the corresponding activities at EN side.
The result is shown in Figure~\ref{fig:createextent}. There
are five RPC calls handled by the same thread. They are
create extent, three append extent and seal extent. Using
ExtentID, we can only distinguish at extent operation level,
so the five RPC handling process are treated as one task
instance.

%\vskip 1em
%\textbf{Lessons:}
\lession
1) the choice of key is important. The result task model is
sensitive to the choice of key.

2) the task boundary has a phase-shift with real task
boundary. Because some preparation steps doesn't know the
key and value that early.

3) we can combine scalpel and data hierarchy together. Using
scalpel to automatically find dependency, and use data
hierarchy to find task boundary. The advantage is, data
hierarchy is predefined by system design and the result
should be more precise than bottom-up mining.

4) task model in this way is an overlay above low level
synchronization operations.

5) using ExtentID to analyze EN is too coarse.

\subsection{Guide on debugging}
\notes{
using the model to guide on debugging cosmos network
library.
}

Methodology: We have to identify the boundary of client
threads (who enqueue message) and worker threads (who really
send and receive message). So we send CsExtentInfo for a
random set of extents, so using ExtentID as key, we can
separate different tasks for both client threads and worker
threads.

Using our method we can only show that the worker threads
are working in a synchronized way. No overlay between tasks.
The root cause has to be invetigated manually.

We do it in three steps:

1. make sure client threads is faster than worker, so the
client threads are not bottleneck. We
maintain a flow control counter among client threads, and
see that it is alway near maximum value.

1.5. client threads enqueu the message and ignore it, means
we use asynchronous send setting.

2. worker's task segment is not interleaved, even for
different threads.

3. examine worker's processing model. We find that a
processor object is shared among different workers, so it is
a scarce resource. To send or receive a message, worker
threads must obtain the shared processor object to `run' the
message.

