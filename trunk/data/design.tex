% vim:tw=60

\section{Design}
\label{sec:design}

\begin{figure}
\centering
\includegraphics[height=2in]{design}
\caption{Design Overview}
\label{fig:design}
\end{figure}

Our design is summarized in Figure~\ref{fig:design}. We
first extract data from system logs as streams of (key,
value) tuples. Then we try to mine hierarchical relations
among keys. The mined relations can be directly translated
to task models. Applying the task models on logs, we
generate a set of task instances represented as an array of
log items.

\subsection{Extract key-value pairs}
\notes{value format are limited, we can find value part
easily, and track back in the text to find its key name.}

System logs contains a lot of information on system
activities. The log items mainly describes who (threads,
event handlers) are performing some operations (as function
name or in human language) on a set of data, with extra
information such as operation result (return code).

Our tool can infer the hierarchical relations among the data
on which system operates and generat task models using
inferred data hierarchy.

To do the inferrence, we have to first extract data part
from log. It will be represented as (key, value) tuples,
with key as data identifer and value as current content.

Different system have different log format. We describe how
to extract data from cosmos log in (key, value) format. The
principle described here can be adopted to analyze other
kinds of log. \notes{At the end of the section, we will
discuss this problem in general.}

\begin{verbatim}
d,12/30/2008 14:51:22.949,CosmosClient,
CosmosClientDebug,SrcFile="cosmosstream.cpp"
SrcFunc="CosmosStream::StartCsmAppendJob" 
SrcLine="570" Pid="3000" Tid="9144"
TS="0x01C96A4B0702ECC2" String1="CSM append
POSTED: opId: 3, streamId:
{A8593030-1B74-4D40-B76B-52F4F7240513}, name:
cosmos://srg-sna10/vol1/graphviz-2.20.2.exe,
length: 1045679, offset: unknown,
waitForSeal: 1, status: OK"
\end{verbatim}

The above shows a typical log item picked from cosmos.  The
cosmos log can be divided into two parts. The first half has
fixed format, which records log level, time, log category
and a short title. Followed by the location of the log in
source file, and runtime parameters. The second half is
contained in \texttt{String1} field. It is written by
developer and not well structured. It is usually interleaved
with descriptive texts and programs states in (key, value)
pairs.

It is not straightforward to extract the (key, value) pairs.
The developer can record (key, value) in several formats. In
general, it is written as \texttt{key SEP1 value SEP2}. SEP1
and SEP2 have mutiple choices. It is not easy to determine
which word is a key, otherwise we can do the job easily. A
key may look similar to an irrelevant words, such as
\texttt{POSTED:} and \texttt{opId:}.

We use a novel method to extract the (key, value) pairs. It
is based on the observation that the value part has limited
formats, such as an integer, a hexadecimal or a GUID, and it
is easy to be match by regular expression. Once the value
part is located, we can track back in the text to find its
corresponding key.

Currently, we choose to extract (key, value) pairs whose
value parts are numbers but not text. Our considerations
are: a) values as text are more descriptitive and have
little use in inferring data hierarchy in later steps. b)
SEP1 and SEP2 may be both blanks. In such cases,
text words, keys and values are messed up and they cannot be
distinguished using simple rules.

\notes{key alias: one key has multiple names, key name
collision: multiple key has the same name.  we can solve
above two problems using some key mapping scheme, but it
requires manual work and one have to familiar with log and
keys. our suggestion: regular key definition}

\subsection{Mining hierarchical relation of keys}

Some of the keys extracted from log have hierarchy
relations. For example, to complete a \texttt{Session}, it
is splitted into subtasks which are designated by different
\texttt{opId}. There are similar relations with
\texttt{StreadID} and \texttt{ExtentID}. We can use the
data hierarchy to deduce task hierarchy. Two keys have
hierarchical relations are denoted by $>$, for example,
\texttt{Session} $>$ \texttt{opId}.

After the previous step, we get a stream of (key, value)
pairs in their order of appearance in log file. Activities
from multiple threads may be logged into the same log file.
We split (key, value) streams by thread and mine different
sub-streams separately. The mined results are combined
together.

We use two heuristics to mine data hierarchy among keys.
They are the necessary conditions for two keys to have
hierarchical relation.
\begin{itemize}
\item If keyS $>$ keyP, then keyS comes before keyP.
\item If keyS $>$ keyP, then there're strict 1-to-many
mapping between keyS and keyP value set.
\end{itemize}
The intuition is, if keyS $>$ keyP, one will see keyS first,
and a series of keyP with different values, and then keyS,
with another value, and then a series of keyP. 

The mining algorithm takes (key, value) stream as input and
outputs (keyS, keyP, R) tuples, indicating keyS $>$ keyP
with rank R.

\begin{verbatim}
A a1
B b1
B b2
A a2
B b3
\end{verbatim}
\notes{this will replaced by example below}

There above (key, value) streams servers as an simple demo
of mining algorithm. After mining, we will get (A, B, 3).
Because A appears before B, A is a possible parent of B. The
rank 3 is calulated as the cardinality of (valueA, valueB)
set: \{(a1, b1), (a1, b2), (a2, b3)\}

The rank algorithm works as follows. It scans through the
(key, value) stream and maintains an array of keys. Once a
key is spotted for the first time, it is appended to the key
array. A key is a possible parent for all the keys after it
in the array (heuristic 1). In the scan process, the algorithm also
accumulate an array of (valueS, valueP) for each (keyS, keyP)
pairs. A new (keyP, valueP) will generate multiple (valueS,
valueP) for each keyS before keyP in the key array.

Now for each (keyS, keyP) pair, we have a corresponding
(valueS, valueP) array. To apply heuristic 2, we have to
justify whether valueS and valueP have strict 1-many
mappings. If yes, we use size of (valueS, valueP) array
as the rank of (keyS, keyP), if not, we just ignore the
(keyS, keyP) pair.

\notes{pseudo code of mining algorithm}

We give a more complete example here.
\begin{verbatim}
Session s1
opId 1
StreamID x1
opId 2
ExtentID y1
opId 3
ExtentID y2

Session s2
opId 4
StreamID x2
opId 5
ExtentID y3
opId 6
ExtentID y4
\end{verbatim}
The above example emulate the (key, value) stream we see in
cosmos client log. When the client receives a command, it
starts a new session, opens the specified stream in next
operation step, and process extents of the stream in the
following operation steps.

We sucessfully mined out StreamID $>$ ExtentID with rank 4
and Session $>$ opId with rank 6. Session has no relation
with StreamID, because multiple Session may operate on the
same StreamID. The similar argument apply for (Session,
ExtentID), (opId, StreamID) and (opId, ExtentID).

For (key, value) streams generated form real world log, the
mined result may contain a lot false positives.

\notes{Have to find some way to automatically filter out
false positives. For example, if (err, 0x0) is inserted
after each Session, we will see Session $not >$ err, but
err $>$ opId and Session $>$ opId, using transitive rule?}

\notes{cannot reduce all false positives. patch 1: user
specify a subset of all keys. patch 2: user manually delete
false pairs}

\subsection{Construct hierarchical task models}

\notes{task model can be expanded to many task instances. The
boundary of a task instance defined by value flip point.}

After the previous step, we mined out a set of data
hierarchy relations. The relations can be translated
directly to hierarchies of tasks which process the data. 
If we have keyS $>$ keyP, and use Task(keyS) to denote task
that process keyS, then we have Task(keyS) $:=$
Task(keyP)$+$, in short keyS $:=$ keyP+

We apply the mined data hierarchy on the log to construct
task models. We first split log items into groups by highest
level key. The group begins at the new value of a key and
last until another value is met. We apply the process
recursively within each group to construct hierarchical task
models.

%join the pairs together

The choice of which data hierarchy to apply is left to user.
The choice depends on user's concentration. The user are not
limited to mined result. Other hierarchy relations can be
specified. For example, one can combine Session, opId,
StreamID, ExtentID together, and write the relation as
Session $:=$ opId$+$, opId $:=$ StreamID$|$ExtentID.

\notes{the result task boundary is an approximation, has a
shift with `real' boundary.}

\subsection{Put things together}

From the demo to task model and then task instances


