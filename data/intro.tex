% vim:tw=60

\section{Introduction}
\label{sec:intro}

\notes{Main idea: data hierarchy (Session$>$opId) can be
translated into task models (Task(Session) $:=$ Task(opId+).
Task model can be instantiated into many distances.  We
implement the idea on system logs.}

%As industry is moving towards \textit{cloud computing}, many
%players in the industry are building large and complex data
%center applications on top of clusters of commodity PCs.
%Ensuring the correctness and performance of the applications
%are critical to providing sustained service to clients.
%However, bugs have been challenging service developers and
%maintainers continually.

Distributed systems are the key enabler of most
today's Internet Services. They run over many machines,
exploit and schedule the machine resources to provide 
high-throughput, low latency services, and have to cope 
with many kinds of failures. Because of the system scale
and the critical service requirement, the design and 
implementation of these systems is prone to have bugs
that lead to unexpected execution behaviors. 
The root causes of bugs are sometimes hidden behind
the convoluted application logic, and takes long time
to find out. 

Understanding runtime behaviour of distributed systems 
is key to design verification, detection of correctness
and performance problems, and tracking down the root cause
of bugs. However, it is non-trivial, even for the developers
who implement the system, to fully understand the system 
logic. This is because of the inherent complexity 
in system design and runtime behaviors, and that 
the system is typically developed by a group of people
and keep evolving in a daily manner.
Especially, distributed systems usually adopt a layered
and tiered design, in which a user request is accomplished
through multiple stages, each stage involving a hierarchical
functional abstractions. A high-level function or user-level
task is achieved by low-level ones, which may execute
concurently and communicate across the boundaries of machines, 
processes, and threads. All of these issues contribute to the
difficulty in understanding system behaviors.

Existing approaches have shown that modeling and representing
system behaviors with hierarchical task models help developers
better understand and verify system behaviors. For example,
Pip~\cite{} allows developers to define nested task flows
with associated properties as ``expectations'', which are used 
to detect violations.
By this means, developers are able to specify and verify 
system properties at an appropriate layer, instead of


of 
For example, 
Our previous work ...
shown the benefits in verifying .. and understanding the
root cause. 


Hierarchical representation is justified by existing
work (pip) and our previous work. In this paper, we further
explore the idea


This paper present the tool for developer, tester, 
and system administrator to explore 





Understanding runtime behaviour of the complex system is key
to verify system design, debug its correctness and
performance problems. By tracking task pieces and their
causal dependencies, we can construct task flow by linking
together pieces of its execution throughout the system.  In
our previous work, we further developed techniques to
automatically tracking tasks and infer hierarchical task
models. Using the task models, developers can better
understand the structures of components and their
dependencies, and use debugging tools to instrument the
system and verify the behavior of tasks at appropriate
layers.

The production system contains abundant logging information
on system status, but it is not fully explored yet. It is
useful for two reason. First, the log is added by developers
who are familiar with the system.  The resulting log is a
faithful records of system runtime behaviour. Second, log
usually contains both state report and high level
descriptions. The derived task models is of value for both
automatic processing and human understanding.

The hierarchical structure of tasks is often consist with
the hierarchy of data processed by tasks. For example. In
cosmos, data are organized as streams and streams are
consisted of extents. By inspecting cosmos logs, task that
processing a stream is splitted into subtasks. The first
subtask do some stream level processing (open, etc.), and
the following tasks process extents in the stream. But the
task boundaries are not marked in the log.

By mining and leveraging data hierarchy, we can use the
information to infer the task hierarchy. A log item which
starts to process a stream marks the begin of a task. The
task lasts before the log item which process another stream.
Within the task, it is splitted into subtasks at
extent-processing boundary.

In this paper, we present a method for automatically infer
data hierarchy recorded in system log and use the
information to construct task models.  We also describe our
experiences in using the inferred task models to
understanding the system design and debug performance
problems.

\comment{
It faces several challenges. First, logs are not
written in well strucutured form. Second, log contains a lot
information other than data identifer, and the noises must
be reduce automatically with best effort.

}

\comment{
and build hierarchical task models to better
understand and check system runtime behaviour.

Meanwhile, debugging correctness and performance problems
for the systems are difficult.

System log is a rich source of information for understanding
system runtime behaviour.

Researchers have proposed several techniques, but system log
is not explored much.

In this paper, we try to build hierarchical task model
through logs.

Contribution/Highlights:

Goal: Understanding system behaviour by exploiting existing
system logs

magpie: more details on low level properties d3s: customized
log point pip: manual annotation

our advangtage: 

existing log more on high level semantic
}
